{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Named Entity Recognition (NER) for Corridos\n",
        "The following Notebook was created by Group Four in IS578: Introduction to Digital Humanities at the University of Illinois, Urbana-Champaign (Fall 2022). It marginally adapts code from Melanie Walsh's free online textbook: [Introduction to Cultural Analytics and Python](https://melaniewalsh.github.io/Intro-Cultural-Analytics/05-Text-Analysis/Multilingual/Spanish/02-Named-Entity-Recognition-Spanish.html).\n",
        "\n",
        "A special thanks to Dr. Zoe LeBlanc for guiding us to resources this semester, especially Walsh's text.\n",
        "\n",
        "## Overview\n",
        "\n",
        "Named Entity Recognition (NER) is a common method of Natural Language Processing (NLP). It identifies various objects in text, such as people, places, organizations, or any other proper nouns. There are several Python libraries that enable NER, but here we focus on spaCy. You can learn more about spaCy [here](https://spacy.io/) and [here](https://en.wikipedia.org/wiki/SpaCy). It is one of the most popular NLP libraries in Python.\n",
        "\n",
        "For our project, we used NER to identify places mentioned in a corpus of corridos. Corridos are a traditional form of Mexican music and folklore that often describe historic events, people, and places. Using NER, we hoped to extract data that could be transferred to geospatial mappings as a way to represent corridos and the significance of the places they mention.\n",
        "\n",
        "The program in this notebook was useful but not perfect. Our training data was taken from spaCy's free pipelines, and while it was good at finding almost all the named entities, it was not particularly accurate at categorizing them between persons (PER), organizations (ORG), locations (LOC), or miscellaneous (MISC). If we had more time and a larger corpus, we would have attempted to create our own training data to improve these results. This could be a project for the future, if any of our group members are so inclined.\n",
        "\n",
        "There was also no way for the program to specify locations with enough detail to automate the mapping process; that is, in order to automatically map every place at once, we would have needed city, state, country, longitude, and latitude data. Given the often implied or symbolic nature of this information in our corpus, it was beyond the ability of any computer to identify on its own. Still, our NER program was useful to us because it saved us the tedious work of identifying all the named entities through reading. We still had to double-check the categorization results and manually search place names in Google Maps to verify their accuracy in relation to the corridos, but at least the program in this notebook provided the list of named entities from which to begin the manual work.\n",
        "\n",
        "Finally, we put this program into a Colab notebook so every group member could follow along, no matter their Python experience. Given this prioritization of accessibility, we have kept the script short and concise to its primary task. Minor variations were used before we established this concise draft–variations that involved different input methods, compared other NER libraries such as NLTK, and attempted different training data. Such variations could still be added to this program. Its use is also not limited to corridos. If you hope to adapt this script to other projects, we encourage you to review Melanie Walsh's [Introduction to Cultural Analytics and Python](https://melaniewalsh.github.io/Intro-Cultural-Analytics/05-Text-Analysis/Multilingual/Spanish/02-Named-Entity-Recognition-Spanish.html). Also, feel free to contact [Matthew Kollmer](https://matthewkollmer.com). He will be happy to assist if he can (but please know he is still learning how to program in Python, too).\n"
      ],
      "metadata": {
        "id": "515UqeV1wDSd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import Spacy\n",
        "\n",
        "To begin our analysis, we need to import spaCy and download our training data. Importing spaCy allows us to use all of the predetermined functions in the spaCy library. Downloading spaCy's training model helps the spaCy functions determine named entities based on prior encoding. If you want to explore other training data, check out spaCy's list [here](https://https://spacy.io/models/es). To utilize other training data, simply change the code below that says \"es_core_news_md\" with whatever training data you prefer."
      ],
      "metadata": {
        "id": "S3aOCcrDFcOD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "!python -m spacy download es_core_news_md\n",
        "\n",
        "import es_core_news_md\n",
        "\n",
        "SPANISH_NER_MODEL = spacy.load('es_core_news_md')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MpeDOprE93ig",
        "outputId": "08858fa7-af99-459f-fa8a-833982240bdf"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-11-19 22:37:26.084438: E tensorflow/stream_executor/cuda/cuda_driver.cc:271] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting es-core-news-md==3.4.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/es_core_news_md-3.4.0/es_core_news_md-3.4.0-py3-none-any.whl (42.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 42.3 MB 1.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: spacy<3.5.0,>=3.4.0 in /usr/local/lib/python3.7/dist-packages (from es-core-news-md==3.4.0) (3.4.2)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->es-core-news-md==3.4.0) (3.0.8)\n",
            "Requirement already satisfied: thinc<8.2.0,>=8.1.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->es-core-news-md==3.4.0) (8.1.5)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->es-core-news-md==3.4.0) (2.23.0)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->es-core-news-md==3.4.0) (3.3.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->es-core-news-md==3.4.0) (57.4.0)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->es-core-news-md==3.4.0) (1.0.3)\n",
            "Requirement already satisfied: typing-extensions<4.2.0,>=3.7.4 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->es-core-news-md==3.4.0) (4.1.1)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->es-core-news-md==3.4.0) (1.21.6)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->es-core-news-md==3.4.0) (2.4.5)\n",
            "Requirement already satisfied: pathy>=0.3.5 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->es-core-news-md==3.4.0) (0.6.2)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.10 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->es-core-news-md==3.4.0) (3.0.10)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->es-core-news-md==3.4.0) (1.10.2)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->es-core-news-md==3.4.0) (1.0.9)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->es-core-news-md==3.4.0) (2.0.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->es-core-news-md==3.4.0) (21.3)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.9.1 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->es-core-news-md==3.4.0) (0.10.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->es-core-news-md==3.4.0) (2.11.3)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->es-core-news-md==3.4.0) (4.64.1)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->es-core-news-md==3.4.0) (2.0.7)\n",
            "Requirement already satisfied: typer<0.5.0,>=0.3.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->es-core-news-md==3.4.0) (0.4.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from catalogue<2.1.0,>=2.0.6->spacy<3.5.0,>=3.4.0->es-core-news-md==3.4.0) (3.10.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->spacy<3.5.0,>=3.4.0->es-core-news-md==3.4.0) (3.0.9)\n",
            "Requirement already satisfied: smart-open<6.0.0,>=5.2.1 in /usr/local/lib/python3.7/dist-packages (from pathy>=0.3.5->spacy<3.5.0,>=3.4.0->es-core-news-md==3.4.0) (5.2.1)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->es-core-news-md==3.4.0) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->es-core-news-md==3.4.0) (2022.9.24)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->es-core-news-md==3.4.0) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->es-core-news-md==3.4.0) (3.0.4)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.7/dist-packages (from thinc<8.2.0,>=8.1.0->spacy<3.5.0,>=3.4.0->es-core-news-md==3.4.0) (0.0.3)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.7/dist-packages (from thinc<8.2.0,>=8.1.0->spacy<3.5.0,>=3.4.0->es-core-news-md==3.4.0) (0.7.9)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.7/dist-packages (from typer<0.5.0,>=0.3.0->spacy<3.5.0,>=3.4.0->es-core-news-md==3.4.0) (7.1.2)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->spacy<3.5.0,>=3.4.0->es-core-news-md==3.4.0) (2.0.1)\n",
            "Installing collected packages: es-core-news-md\n",
            "Successfully installed es-core-news-md-3.4.0\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('es_core_news_md')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Input Corrido\n",
        "\n",
        "Now we need to choose our text for NER analysis. There are a number of ways to input texts, but here we've made it easy. Just copy and paste the corrido you want to analyze in between the sets of apostrophes. This allows you to assign the corrido to an analyzable object–a string of characters–that we've named \"corrido\" below."
      ],
      "metadata": {
        "id": "yEFjLBXgCmt_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "corrido = '''\n",
        "CORRIDO DE MACARIO ROMERO \n",
        "\n",
        "¡Válgame San Juan, qué veo, \n",
        "cuánto yaqui de guarache \n",
        "y cuánto maldito apache \n",
        "con sus flechas de trofeo ! \n",
        "\n",
        "¡Abran paso que ahí voy yo,\n",
        " ni a los yaquis tengo miedo, \n",
        "yo soy Macario Romero \n",
        "que al mismo diablo corrió! \n",
        "\n",
        "Voy a cantar, mis amigos, \n",
        "con cariño verdadero, \n",
        "para recordar del hombre \n",
        "que fué Macario Romero. -\n",
        "\n",
        "Era amigo de los hombres, \n",
        "los quería de corazón, \n",
        "por un amor lo mataron, \n",
        "lo mataron a traición. \n",
        "\n",
        "Dijo Macario Romero: \n",
        "oiga, mi general Plata, \n",
        "concédame una licencia, \n",
        "para ir a ver a mi chata.\n",
        "\n",
        "El general Plata dijo: \n",
        "Macario ¿qué vas a hacer? \n",
        "Te van a quitar la vida \n",
        "por una ingrata mujer.\n",
        "\n",
        "Dijo Macario Romero, \n",
        "dando vuelta a una ladera: \n",
        "al cabo ¿qué me han de hacer,\n",
        " si es pura sarracuatera ? \n",
        "\n",
        "Le dijo el general Plata \n",
        "sin mi licencia no vas; \n",
        "mas si llevas tu capricho, \n",
        "en tu salud lo hallarás. \n",
        "\n",
        "Dijo Macario Romero \n",
        "al salir de la garita : \n",
        "yo voy a ver a mi chata, \n",
        "a mí nadie me la quita. \n",
        "\n",
        "Dijo Jesusita Llamas: \n",
        "papá, ahí viene Macario, \n",
        "desde a leguas lo conozco\n",
        "en su caballo melado. \n",
        "\n",
        "Don Vicente Llamas dijo: \n",
        "¡Jesús! ¿qué plan le pondremos?\n",
        " Vamos haciéndole un baile \n",
        "y así ya lo mataremos. \n",
        "\n",
        "Llega Macario Romero,\n",
        "lo convidan a bailar, \n",
        "y cuando está desarmado, \n",
        "le comienzan a tirar:\n",
        "\n",
        "Dijo Macario Romero : \n",
        "acábame de matar, \n",
        "que al cabo mi hermano Pedro \n",
        "es el que me ha de vengar. \n",
        "\n",
        "¡Cobardes! así son buenos, \n",
        "me asesinan a traición, \n",
        "por viles y montoneros, \n",
        "allá lo verán con Dios. \n",
        "\n",
        "Sepan que muero en mi ley, \n",
        "como se mueren los hombres, \n",
        "viles, traidores, collones, \n",
        "solos los quisiera ver. \n",
        "\n",
        "¡Adiós, chata de mi vida; \n",
        "adiós, mi bello lucero, \n",
        "adiós, mi prenda querida, \n",
        "Jesús, Jesús, que me muero! \n",
        "\n",
        "Y diciendo esto expiró, \n",
        "el valiente de Macario, \n",
        "que en garras de un sanguinario, \n",
        "por su desgracia cayó. \n",
        "\n",
        "Jesusita Llamas dijo: \n",
        "ahora sí quedamos bien, \n",
        "ya mataron a Macario, \n",
        "mátenme ahora a mí también. \n",
        "\n",
        "¡Bandidos, sigan conmigo, \n",
        "morirme, morirme quiero! \n",
        "para qué quiero la vida \n",
        "sin mi Macario Romero!\n",
        "\n",
        "Brazo a brazo, frente a frente \n",
        "debían haberlo agarrado, \n",
        "y no traicioneramente, \n",
        "como lo han asesinado. \n",
        "\n",
        "Don Jesús Aceves dijo: \n",
        "vamos levantando una acta, \n",
        "que matamos a un bandido, \n",
        "de los del general Plata. \n",
        "\n",
        "Ya nos quitamos del frente \n",
        "a ese famoso escorpión, \n",
        "que la echaba de valiente, \n",
        "cuando los cogía a traición. \n",
        "\n",
        "Ya con esta me despido, \n",
        "porque llorar ya no quiero \n",
        "la muerte de ese valiente, \n",
        "de ese valiente Romero.\n",
        "'''"
      ],
      "metadata": {
        "id": "AoIDnpQo4Mau"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Apply Model to Corrido\n",
        "\n",
        "Now we need to apply our model to our corrido and create an object with all of the results. The code below does just that–it puts the corrido into the model as a parameter and assigns the results to the object \"corrido_entities\"."
      ],
      "metadata": {
        "id": "lzYo-p1ADw0s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "corrido_entities = SPANISH_NER_MODEL(corrido)"
      ],
      "metadata": {
        "id": "_44IuVyF4Prn"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Then if we use the spaCy method \"ents\" on our new object, we'll be given a list of named entities. Simple as that!"
      ],
      "metadata": {
        "id": "xT7jIFnyFGxE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "corrido_entities.ents"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MgzzocC56ybh",
        "outputId": "5c8faf41-1615-46fa-ed5a-181c7f2e1334"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(CORRIDO,\n",
              " Macario Romero,\n",
              " Macario Romero,\n",
              " Dijo Macario Romero,\n",
              " Plata,\n",
              " Macario,\n",
              " Dijo Macario Romero,\n",
              " Plata,\n",
              " Dijo Macario Romero,\n",
              " Jesusita Llamas,\n",
              " Macario,\n",
              " Don Vicente Llamas,\n",
              " Llega Macario Romero,\n",
              " Macario Romero,\n",
              " Pedro,\n",
              " Dios. \n",
              " \n",
              " Sepan,\n",
              " Jesús,\n",
              " Macario,\n",
              " Jesusita Llamas,\n",
              " Macario,\n",
              " ¡Bandidos,\n",
              " Macario Romero!\n",
              " \n",
              " Brazo,\n",
              " Don Jesús Aceves,\n",
              " general Plata.,\n",
              " Romero.)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## spaCy NER Categories\n",
        "\n",
        "If we want to see which NER categories each named entity has been classified under, we can use a for-in loop that returns each entity next to its category. Keep in mind, these are built-in categories and may not be exactly correct. They are also given acronyms that may need clarification. For a full list of these categories with brief explanations, check out [this part](https://www.kaggle.com/code/curiousprogrammer/entity-extraction-and-classification-using-spacy?scriptVersionId=11364473&cellId=9) of another notebook on spaCy."
      ],
      "metadata": {
        "id": "1WnNWPNmFzWI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for named_entity in corrido_entities.ents:\n",
        "    print(named_entity.label_, named_entity)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mil5D9-_7B5T",
        "outputId": "b73779dd-d0b3-40dc-981e-fa99cf77049c"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ORG CORRIDO\n",
            "PER Macario Romero\n",
            "PER Macario Romero\n",
            "PER Dijo Macario Romero\n",
            "PER Plata\n",
            "PER Macario\n",
            "PER Dijo Macario Romero\n",
            "PER Plata\n",
            "PER Dijo Macario Romero\n",
            "PER Jesusita Llamas\n",
            "LOC Macario\n",
            "PER Don Vicente Llamas\n",
            "PER Llega Macario Romero\n",
            "PER Macario Romero\n",
            "PER Pedro\n",
            "LOC Dios. \n",
            "\n",
            "Sepan\n",
            "PER Jesús\n",
            "PER Macario\n",
            "PER Jesusita Llamas\n",
            "PER Macario\n",
            "LOC ¡Bandidos\n",
            "PER Macario Romero!\n",
            "\n",
            "Brazo\n",
            "PER Don Jesús Aceves\n",
            "ORG general Plata.\n",
            "MISC Romero.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Conclusion\n",
        "\n",
        "As you can see, this final part of the process is not perfect, but the solution (project-specific training data) is beyond the scope of this semester. Still, this NER method saved us a fair amount of time because double-checking these named entities from a list was faster than trying to identify them through close reading. We were therefore grateful to have discovered these methods.\n",
        "\n",
        "We also benefitted from the exposure to Python and spaCy. As has been true for so much of this semester, our group found lots of things we hope to build on in the future."
      ],
      "metadata": {
        "id": "ZlhRq8vPL_ip"
      }
    }
  ]
}